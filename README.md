# 1. What this Program does?
parallelize a sequential version of a two-dimensional wavediffusion program, using a hybrid form of MPI and OpenMPI.
## Schroedinger's Wave Dissemination
Assume the water surface in a two-dimensional square bucket. To simulate wavedissemination over this water surface, let’s partition this square in mesh and thusinto N-by-N cells. Each cell(i, j) where 0 < i, j < N-1 maintains the height of itswater surface. A wave is disseminated north, east, south, and west of each cell,and therefore cell(i, j) computes its new surface height from the previous heightof itself and its four neighboring cells: cell(i+1, j), cell(i-1, j), cell(i, j+1) andcell(i, j-1). Let Zt_i,j, Zt-1_i,j, and Zt-2_i,j be the surface height of cell(i, j) attime t, time t-1, and time t-2 respectively. No wave at cell(i, j) at time t meansZt_i,j = 0.0. The water surface can go up and down between 20.0 and -20.0through the wave dissemination.
# 2. Parallelization strategies 
1. Array was evenly distributed to MPI nodes. Every node gets a portion as a size of array/ sizes of MPI nodes.each portion’s start and end index are calculated  then pass them together with max time, interval and rank to calculate() function.     
2. In calculate() function, Every node computes data separately for time 0 and 1. Therefore, each slave process can start immediately without waiting for the master process to pass the initial data. 
3. At the end of the interval, all salve process send data back to the master process. The master process receives data then print it out. 
4. Handing exchange data between stripes:   • Each process send its start row of the table z to their left neighbor and its end row of the table z to right neighbor• Each process receives its start -1 row of the table z from their left neighbor and receive its end + 1 row of the table z from right neighbor• For rank 0 process, it doesn’t need to send/receive from its left neighbor since it doesn’t have left neighbor. Same is to the last slave process which doesn’t have right neighbor. • All processes send data first and then receive data from their neighbors, because the receive call would block the process. 
5. Identify time-consuming functions and implement Open MP. I create parallel regions for all for loops inside calculate() function. When time is greater than 2, the processes need to exchange binary data with its neighbors. A critical section is needed to ensure only one thread go through MPI parallel region. Otherwise, race condition happens. I set the parallel region under the second for loop. It creates a critical section where only one thread running the MPI code.

# Performance 
Performance improvement with four machines: 3968882/ 1095522=3.62
Performance improvement with four machines with multithreading: 3968882/ 432718 = 9.17
